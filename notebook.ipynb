{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "759b8900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import os\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "import stempeg\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d46c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b83961a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdf299ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WaveNet(\n",
       "  (start_conv): Conv1d(2, 64, kernel_size=(1,), stride=(1,))\n",
       "  (blocks): ModuleList(\n",
       "    (0): WaveNetBlock(\n",
       "      (conv_filter): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same)\n",
       "      (conv_gate): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same)\n",
       "      (conv_res): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (conv_skip): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (1): WaveNetBlock(\n",
       "      (conv_filter): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(2,))\n",
       "      (conv_gate): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(2,))\n",
       "      (conv_res): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (conv_skip): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (2): WaveNetBlock(\n",
       "      (conv_filter): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(4,))\n",
       "      (conv_gate): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(4,))\n",
       "      (conv_res): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (conv_skip): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (3): WaveNetBlock(\n",
       "      (conv_filter): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(8,))\n",
       "      (conv_gate): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(8,))\n",
       "      (conv_res): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (conv_skip): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (4): WaveNetBlock(\n",
       "      (conv_filter): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(16,))\n",
       "      (conv_gate): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(16,))\n",
       "      (conv_res): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (conv_skip): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (5): WaveNetBlock(\n",
       "      (conv_filter): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(32,))\n",
       "      (conv_gate): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(32,))\n",
       "      (conv_res): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (conv_skip): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (6): WaveNetBlock(\n",
       "      (conv_filter): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(64,))\n",
       "      (conv_gate): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(64,))\n",
       "      (conv_res): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (conv_skip): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (7): WaveNetBlock(\n",
       "      (conv_filter): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(128,))\n",
       "      (conv_gate): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(128,))\n",
       "      (conv_res): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (conv_skip): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (8): WaveNetBlock(\n",
       "      (conv_filter): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(256,))\n",
       "      (conv_gate): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(256,))\n",
       "      (conv_res): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (conv_skip): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (9): WaveNetBlock(\n",
       "      (conv_filter): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(512,))\n",
       "      (conv_gate): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, dilation=(512,))\n",
       "      (conv_res): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (conv_skip): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       "  (end_conv1): Conv1d(64, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (end_conv2): Conv1d(256, 2, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class WaveNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation):\n",
    "        super(WaveNetBlock, self).__init__()\n",
    "        self.dilation = dilation\n",
    "        self.conv_filter = nn.Conv1d(in_channels, out_channels, kernel_size, dilation=dilation, padding='same')\n",
    "        self.conv_gate = nn.Conv1d(in_channels, out_channels, kernel_size, dilation=dilation, padding='same')\n",
    "        self.conv_res = nn.Conv1d(out_channels, in_channels, 1)  # Residual connection\n",
    "        self.conv_skip = nn.Conv1d(out_channels, out_channels, 1)  # Skip connection\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply dilated convolutions\n",
    "        filter_output = torch.tanh(self.conv_filter(x))\n",
    "        gate_output = torch.sigmoid(self.conv_gate(x))\n",
    "        gated_output = filter_output * gate_output\n",
    "        \n",
    "        # Residual and skip connections\n",
    "        residual = self.conv_res(gated_output)\n",
    "        skip_connection = self.conv_skip(gated_output)\n",
    "        output = x + residual\n",
    "        return output, skip_connection\n",
    "\n",
    "class WaveNet(nn.Module):\n",
    "    def __init__(self, num_blocks, num_layers, in_channels, out_channels, residual_channels, skip_channels, kernel_size):\n",
    "        super(WaveNet, self).__init__()\n",
    "        self.num_blocks = num_blocks\n",
    "        self.num_layers = num_layers\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.residual_channels = residual_channels\n",
    "        self.skip_channels = skip_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        \n",
    "        self.start_conv = nn.Conv1d(in_channels, residual_channels, kernel_size=1)\n",
    "        \n",
    "        self.blocks = nn.ModuleList([\n",
    "            WaveNetBlock(residual_channels, residual_channels, kernel_size, 2 ** i)\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.end_conv1 = nn.Conv1d(residual_channels, skip_channels, kernel_size=3, padding=1)\n",
    "        self.end_conv2 = nn.Conv1d(skip_channels, out_channels, kernel_size=3, padding=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.start_conv(x)\n",
    "        skip_connections = []\n",
    "\n",
    "        for _ in range(self.num_blocks):\n",
    "            for layer in self.blocks:\n",
    "                x, skip = layer(x)\n",
    "                skip_connections.append(skip)\n",
    "\n",
    "        output = torch.relu(sum(skip_connections))\n",
    "        output = self.end_conv1(output)\n",
    "        output = torch.relu(output)\n",
    "        output = self.end_conv2(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "# Create an instance of the WaveNet model\n",
    "model = WaveNet(num_blocks=3, num_layers=10, in_channels=2, out_channels=2,\n",
    "                residual_channels=64, skip_channels=256, kernel_size=3)\n",
    "model.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47911ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EnergyConservingLoss(input_mix, input_voice, input_noise, generated_voice):\n",
    "    \n",
    "    voice_L = nn.L1Loss()\n",
    "    noise_L = nn.L1Loss()\n",
    "    \n",
    "    voice_diff = 2 * voice_L(generated_voice, input_voice)\n",
    "    noise_diff = noise_L((input_mix - generated_voice), input_noise)\n",
    "    \n",
    "    loss = voice_diff + noise_diff\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f54e8f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_musdb(subset):\n",
    "    \n",
    "    assert subset in ['train', 'test']\n",
    "    \n",
    "    mix = []\n",
    "    noise = []\n",
    "    vocals = []\n",
    "\n",
    "    for filename in os.listdir('musdb18/{}'.format(subset)):\n",
    "        \n",
    "        audio, sample_rate = stempeg.read_stems('musdb18/{}/'.format(subset) + filename, \n",
    "                                                stem_id=[0, 3, 4],\n",
    "                                                out_type=np.float32,\n",
    "                                                duration=20)\n",
    "\n",
    "        mix.append((audio[0].T, sample_rate))\n",
    "        noise.append((audio[1].T, sample_rate))\n",
    "        vocals.append((audio[2].T, sample_rate))\n",
    "                \n",
    "    return mix, noise, vocals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e47490b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 216.00 MiB (GPU 0; 10.91 GiB total capacity; 9.94 GiB already allocated; 200.06 MiB free; 9.96 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1480/1661504229.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_mix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEnergyConservingLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_mix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_voice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1480/3140259466.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m                 \u001b[0mskip_connections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1480/3140259466.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Apply dilated convolutions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mfilter_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mgate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_gate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mgated_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_output\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgate_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 216.00 MiB (GPU 0; 10.91 GiB total capacity; 9.94 GiB already allocated; 200.06 MiB free; 9.96 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "model = WaveNet(num_blocks=3, num_layers=10, in_channels=2, out_channels=2,\n",
    "                residual_channels=32, skip_channels=128, kernel_size=3)\n",
    "model.to(device) \n",
    "\n",
    "train_mix, train_noise, train_vocals = process_musdb('train')\n",
    "\n",
    "#criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for i in range(len(train_mix)):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_mix = torch.tensor(train_mix[i][0]).unsqueeze(0).to(device=device)\n",
    "        input_voice = torch.tensor(train_vocals[i][0]).unsqueeze(0).to(device=device)\n",
    "        input_noise = torch.tensor(train_noise[i][0]).unsqueeze(0).to(device=device)\n",
    "        \n",
    "            \n",
    "        output = model(input_mix)\n",
    "\n",
    "        loss = EnergyConservingLoss(input_mix, input_voice, input_noise, output)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "            \n",
    "        optimizer.step()\n",
    "            \n",
    "\n",
    "    avg_loss = total_loss / len(train_mix)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Avg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(\"Training finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2696bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(train_mix[1][0], rate=train_mix[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ce82b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "isolated = model(torch.tensor(train_mix[1][0]).unsqueeze(0).to(device=device))\n",
    "Audio(isolated.squeeze(0).cpu().detach().numpy(), rate=train_mix[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b779be0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
