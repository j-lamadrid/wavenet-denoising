{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbb7932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wavenet_model import WaveNetModel\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import torchaudio\n",
    "\n",
    "import os\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "import stempeg\n",
    "import numpy as np\n",
    "\n",
    "import librosa\n",
    "from auraloss.time import SNRLoss, SISDRLoss, SDSDRLoss, ESRLoss\n",
    "from auraloss.freq import STFTLoss, MelSTFTLoss, STFTMagnitudeLoss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39f0a869",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cb75e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(2, 64, kernel_size=2, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=2, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        )\n",
    "\n",
    "        # Middle\n",
    "        self.middle = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=2, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=2, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, kernel_size=2, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 64, kernel_size=2, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # Output Layer\n",
    "        self.output_layer = nn.Conv2d(64, 2, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = self.encoder(x)\n",
    "        # Middle\n",
    "        x2 = self.middle(x1)\n",
    "        # Decoder\n",
    "        x3 = self.decoder(x2)\n",
    "        # Output Layer\n",
    "        x4 = self.output_layer(x3)\n",
    "        return x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8f3d472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_musdb(subset):\n",
    "    \n",
    "    assert subset in ['train', 'test']\n",
    "    \n",
    "    mix = []\n",
    "    noise = []\n",
    "    vocals = []\n",
    "\n",
    "    for filename in os.listdir('musdb18/{}'.format(subset))[:1]:\n",
    "        \n",
    "        if filename == '.ipynb_checkpoints':\n",
    "            continue\n",
    "            \n",
    "        # Pull training sample from sparser/quieter region\n",
    "        audio, sample_rate = stempeg.read_stems('musdb18/{}/'.format(subset) + filename,\n",
    "                                                out_type=np.float32,\n",
    "                                                start=30,\n",
    "                                                duration=10)\n",
    "\n",
    "        mix.append((audio[0].T, sample_rate))\n",
    "        noise.append((audio[1].T+audio[2].T+audio[3].T, sample_rate))\n",
    "        vocals.append((audio[4].T, sample_rate))\n",
    "        \n",
    "        # Pull training sample from more populated/louder region\n",
    "        audio, sample_rate = stempeg.read_stems('musdb18/{}/'.format(subset) + filename, \n",
    "                                                out_type=np.float32,\n",
    "                                                start=60,\n",
    "                                                duration=10)\n",
    "\n",
    "        mix.append((audio[0].T, sample_rate))\n",
    "        noise.append((audio[1].T+audio[2].T+audio[3].T, sample_rate))\n",
    "        vocals.append((audio[4].T, sample_rate))\n",
    "        \n",
    "\n",
    "        audio, sample_rate = stempeg.read_stems('musdb18/{}/'.format(subset) + filename, \n",
    "                                                out_type=np.float32,\n",
    "                                                start=45,\n",
    "                                                duration=10)\n",
    "\n",
    "        mix.append((audio[0].T, sample_rate))\n",
    "        noise.append((audio[1].T+audio[2].T+audio[3].T, sample_rate))\n",
    "        vocals.append((audio[4].T, sample_rate))\n",
    "        \n",
    "    mix_out = []\n",
    "    noise_out = []\n",
    "    vocals_out = []\n",
    "\n",
    "    for i in range(len(vocals)):\n",
    "        if np.mean(abs(vocals[i][0][0]) + abs(vocals[i][0][1])) >= 0.05:\n",
    "            mix_out.append(mix[i])\n",
    "            noise_out.append(noise[i])\n",
    "            vocals_out.append(vocals[i])\n",
    "\n",
    "    return mix_out, noise_out, vocals_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7277dd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset (assuming you have a function process_musdb that loads your data)\n",
    "train_mix, train_noise, train_vocals = process_musdb('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2e4d7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WaveNetModel(layers=7,\n",
    "                     blocks=2,\n",
    "                     dilation_channels=64,\n",
    "                     residual_channels=64,\n",
    "                     skip_channels=128,\n",
    "                     end_channels=128,\n",
    "                     classes=2,\n",
    "                     output_length=0,\n",
    "                     kernel_size=2,\n",
    "                     dtype=torch.FloatTensor,\n",
    "                     bias=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53a61b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Avg Loss: 4.9690\n",
      "Epoch [2/1000], Avg Loss: 2.3918\n",
      "Epoch [3/1000], Avg Loss: 2.0793\n",
      "Epoch [4/1000], Avg Loss: 1.9779\n",
      "Epoch [5/1000], Avg Loss: 2.0345\n",
      "Epoch [6/1000], Avg Loss: 1.9322\n",
      "Epoch [7/1000], Avg Loss: 1.8723\n",
      "Epoch [8/1000], Avg Loss: 1.8984\n",
      "Epoch [9/1000], Avg Loss: 1.8180\n",
      "Epoch [10/1000], Avg Loss: 1.7657\n",
      "Epoch [11/1000], Avg Loss: 1.7355\n",
      "Epoch [12/1000], Avg Loss: 1.6941\n",
      "Epoch [13/1000], Avg Loss: 1.6485\n",
      "Epoch [14/1000], Avg Loss: 1.6425\n",
      "Epoch [15/1000], Avg Loss: 1.6886\n",
      "Epoch [16/1000], Avg Loss: 1.6534\n",
      "Epoch [17/1000], Avg Loss: 1.6211\n",
      "Epoch [18/1000], Avg Loss: 1.6470\n",
      "Epoch [19/1000], Avg Loss: 1.6910\n",
      "Epoch [20/1000], Avg Loss: 1.6114\n",
      "Epoch [21/1000], Avg Loss: 1.5770\n",
      "Epoch [22/1000], Avg Loss: 1.7741\n",
      "Epoch [23/1000], Avg Loss: 1.6268\n",
      "Epoch [24/1000], Avg Loss: 1.7201\n",
      "Epoch [25/1000], Avg Loss: 1.7571\n",
      "Epoch [26/1000], Avg Loss: 1.7459\n",
      "Epoch [27/1000], Avg Loss: 1.9820\n",
      "Epoch [28/1000], Avg Loss: 1.8285\n",
      "Epoch [29/1000], Avg Loss: 1.7571\n",
      "Epoch [30/1000], Avg Loss: 1.6970\n",
      "Epoch [31/1000], Avg Loss: 1.6488\n",
      "Epoch [32/1000], Avg Loss: 1.6321\n",
      "Epoch [33/1000], Avg Loss: 1.7959\n",
      "Epoch [34/1000], Avg Loss: 2.1650\n",
      "Epoch [35/1000], Avg Loss: 1.9710\n",
      "Epoch [36/1000], Avg Loss: 2.3381\n",
      "Epoch [37/1000], Avg Loss: 2.2060\n",
      "Epoch [38/1000], Avg Loss: 1.9915\n",
      "Epoch [39/1000], Avg Loss: 1.7710\n",
      "Epoch [40/1000], Avg Loss: 1.7435\n",
      "Epoch [41/1000], Avg Loss: 1.8375\n",
      "Epoch [42/1000], Avg Loss: 1.7715\n",
      "Epoch [43/1000], Avg Loss: 1.8611\n",
      "Epoch [44/1000], Avg Loss: 1.7638\n",
      "Epoch [45/1000], Avg Loss: 1.6761\n",
      "Epoch [46/1000], Avg Loss: 1.5882\n",
      "Epoch [47/1000], Avg Loss: 1.6372\n",
      "Epoch [48/1000], Avg Loss: 1.6843\n",
      "Epoch [49/1000], Avg Loss: 1.5069\n",
      "Epoch [50/1000], Avg Loss: 1.6876\n",
      "Epoch [51/1000], Avg Loss: 1.4951\n",
      "Epoch [52/1000], Avg Loss: 1.4586\n",
      "Epoch [53/1000], Avg Loss: 1.4366\n",
      "Epoch [54/1000], Avg Loss: 1.3932\n",
      "Epoch [55/1000], Avg Loss: 1.4019\n",
      "Epoch [56/1000], Avg Loss: 1.3322\n",
      "Epoch [57/1000], Avg Loss: 1.3484\n",
      "Epoch [58/1000], Avg Loss: 1.3268\n",
      "Epoch [59/1000], Avg Loss: 1.3133\n",
      "Epoch [60/1000], Avg Loss: 1.2960\n",
      "Epoch [61/1000], Avg Loss: 1.2876\n",
      "Epoch [62/1000], Avg Loss: 1.2931\n",
      "Epoch [63/1000], Avg Loss: 1.2919\n",
      "Epoch [64/1000], Avg Loss: 1.2580\n",
      "Epoch [65/1000], Avg Loss: 1.2605\n",
      "Epoch [66/1000], Avg Loss: 1.2452\n",
      "Epoch [67/1000], Avg Loss: 1.2677\n",
      "Epoch [68/1000], Avg Loss: 1.2397\n",
      "Epoch [69/1000], Avg Loss: 1.2757\n",
      "Epoch [70/1000], Avg Loss: 1.2541\n",
      "Epoch [71/1000], Avg Loss: 1.3727\n",
      "Epoch [72/1000], Avg Loss: 1.4161\n",
      "Epoch [73/1000], Avg Loss: 1.3459\n",
      "Epoch [74/1000], Avg Loss: 1.5194\n",
      "Epoch [75/1000], Avg Loss: 1.4822\n",
      "Epoch [76/1000], Avg Loss: 1.3677\n",
      "Epoch [77/1000], Avg Loss: 1.4277\n",
      "Epoch [78/1000], Avg Loss: 1.3627\n",
      "Epoch [79/1000], Avg Loss: 1.3733\n",
      "Epoch [80/1000], Avg Loss: 1.3282\n",
      "Epoch [81/1000], Avg Loss: 1.2952\n",
      "Epoch [82/1000], Avg Loss: 1.2954\n",
      "Epoch [83/1000], Avg Loss: 1.2859\n",
      "Epoch [84/1000], Avg Loss: 1.2818\n",
      "Epoch [85/1000], Avg Loss: 1.2711\n",
      "Epoch [86/1000], Avg Loss: 1.2647\n",
      "Epoch [87/1000], Avg Loss: 1.2547\n",
      "Epoch [88/1000], Avg Loss: 1.2486\n",
      "Epoch [89/1000], Avg Loss: 1.2462\n",
      "Epoch [90/1000], Avg Loss: 1.2391\n",
      "Epoch [91/1000], Avg Loss: 1.2486\n",
      "Epoch [92/1000], Avg Loss: 1.2380\n",
      "Epoch [93/1000], Avg Loss: 1.2264\n",
      "Epoch [94/1000], Avg Loss: 1.2253\n",
      "Epoch [95/1000], Avg Loss: 1.2224\n",
      "Epoch [96/1000], Avg Loss: 1.2193\n",
      "Epoch [97/1000], Avg Loss: 1.2167\n",
      "Epoch [98/1000], Avg Loss: 1.2137\n",
      "Epoch [99/1000], Avg Loss: 1.2204\n",
      "Epoch [100/1000], Avg Loss: 1.2367\n",
      "Epoch [101/1000], Avg Loss: 1.2360\n",
      "Epoch [102/1000], Avg Loss: 1.2587\n",
      "Epoch [103/1000], Avg Loss: 1.2411\n",
      "Epoch [104/1000], Avg Loss: 1.3330\n",
      "Epoch [105/1000], Avg Loss: 1.2910\n",
      "Epoch [106/1000], Avg Loss: 1.2679\n",
      "Epoch [107/1000], Avg Loss: 1.2503\n",
      "Epoch [108/1000], Avg Loss: 1.2347\n",
      "Epoch [109/1000], Avg Loss: 1.2362\n",
      "Epoch [110/1000], Avg Loss: 1.2191\n",
      "Epoch [111/1000], Avg Loss: 1.2219\n",
      "Epoch [112/1000], Avg Loss: 1.2105\n",
      "Epoch [113/1000], Avg Loss: 1.2072\n",
      "Epoch [114/1000], Avg Loss: 1.2074\n"
     ]
    }
   ],
   "source": [
    "# Define your loss function\n",
    "criterion = STFTLoss(fft_size=4096)\n",
    "\n",
    "# Define your optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for i in range(len(train_mix)):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_mix = torch.tensor(train_mix[i][0]).unsqueeze(0).to(device=device)\n",
    "        input_voice = torch.tensor(train_vocals[i][0]).unsqueeze(0).to(device=device)\n",
    "        input_noise = torch.tensor(train_noise[i][0]).unsqueeze(0).to(device=device)\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(input_mix)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = criterion(output, input_voice[:, :, :440928])\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "            \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "            \n",
    "    avg_loss = total_loss / len(train_mix)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Avg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(\"Training finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd78820",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(train_mix[0][0], rate=train_mix[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96b28ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "isolated = model(torch.tensor(train_mix[0][0]).unsqueeze(0).to(device=device))\n",
    "Audio(isolated.squeeze(0).cpu().detach(), rate=train_mix[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf77006c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mix[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf9446e",
   "metadata": {},
   "outputs": [],
   "source": [
    "isolated * 0.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1707330",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(librosa.istft(librosa.stft(train_mix[0][0])), rate=train_mix[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860a9b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_waveform(waveform, sample_rate, title=\"Waveform\", xlim=None, ylim=None):\n",
    "    waveform = waveform.numpy()\n",
    "\n",
    "    num_channels, num_frames = waveform.shape\n",
    "    time_axis = torch.arange(0, num_frames) / sample_rate\n",
    "\n",
    "    figure, axes = plt.subplots(num_channels, 1)\n",
    "    if num_channels == 1:\n",
    "        axes = [axes]\n",
    "    for c in range(num_channels):\n",
    "        axes[c].plot(time_axis, waveform[c], linewidth=1)\n",
    "        axes[c].grid(True)\n",
    "        if num_channels > 1:\n",
    "            axes[c].set_ylabel(f'Channel {c+1}')\n",
    "        if xlim:\n",
    "            axes[c].set_xlim(xlim)\n",
    "        if ylim:\n",
    "            axes[c].set_ylim(ylim)\n",
    "    figure.suptitle(title)\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eaf014",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_waveform(torch.tensor(train_mix[0][0]), sample_rate=train_mix[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a015659",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_waveform(isolated[0].squeeze(0).cpu().detach(), sample_rate=train_mix[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6c1a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4746c278",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea47cce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
